{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365bd693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /home/harinie/.local/lib/python3.10/site-packages (3.6.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/harinie/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: filelock in /home/harinie/.local/lib/python3.10/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/harinie/.local/lib/python3.10/site-packages (from datasets) (2.2.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/harinie/.local/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: packaging in /home/harinie/.local/lib/python3.10/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pandas in /home/harinie/.local/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/harinie/.local/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /home/harinie/.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/harinie/.local/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/harinie/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /home/harinie/.local/lib/python3.10/site-packages (from datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/harinie/.local/lib/python3.10/site-packages (from datasets) (0.31.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/harinie/.local/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/harinie/.local/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/harinie/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/harinie/.local/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/harinie/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/harinie/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/harinie/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/harinie/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/harinie/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/harinie/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/harinie/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/harinie/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/harinie/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac394fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting soundfile\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/harinie/.local/lib/python3.10/site-packages (from soundfile) (2.2.5)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/harinie/.local/lib/python3.10/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/harinie/.local/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Installing collected packages: soundfile\n",
      "Successfully installed soundfile-0.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5fcc672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import csv\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6624628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 998 examples [00:06, 163.66 examples/s]"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "def extract_words_from_fleurs_arabic():\n",
    "    # Load the FLEURS Arabic dataset without decoding audio\n",
    "    dataset = load_dataset(\"google/fleurs\", \"fa_ir\", split=\"train+validation+test\")\n",
    "\n",
    "    # Avoid audio decoding by skipping the 'audio' field\n",
    "    dataset = dataset.remove_columns([\"audio\"])\n",
    "    dataset = dataset.select(range(min(3000, len(dataset))))\n",
    "\n",
    "    word_set = set()\n",
    "    for example in dataset:\n",
    "        transcription = example[\"transcription\"]\n",
    "        words = transcription.strip().split()\n",
    "        for word in words:\n",
    "            word_set.add(word)\n",
    "\n",
    "    # Sort and save\n",
    "    sorted_words = sorted(word_set)\n",
    "    os.makedirs(\"Words\", exist_ok=True)\n",
    "    with open(\"Words/persian.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for word in sorted_words:\n",
    "            f.write(f\"{word}\\n\")\n",
    "\n",
    "    print(f\"Saved {len(sorted_words)} unique words to Words/persian.txt\")\n",
    "\n",
    "# Run the function\n",
    "extract_words_from_fleurs_arabic()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2030720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 10025 unique words to Words/arabic.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def extract_words_from_tsv(tsv_path, output_path):\n",
    "    word_set = set()\n",
    "\n",
    "    with open(tsv_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        for row in reader:\n",
    "            if len(row) < 4:\n",
    "                continue  # Skip malformed rows\n",
    "            transcription = row[3]  # Column 4: normalized transcription\n",
    "            words = transcription.strip().split()\n",
    "            word_set.update(words)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for word in sorted(word_set):\n",
    "            f.write(f\"{word}\\n\")\n",
    "\n",
    "    print(f\"Extracted {len(word_set)} unique words to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "extract_words_from_tsv(\"train.tsv\", \"Words/arabic.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
